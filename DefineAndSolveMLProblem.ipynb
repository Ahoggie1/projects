{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will follow the machine learning life cycle and implement a model to solve a machine learning problem of your choosing. You will select a data set and choose a predictive problem that the data set supports.  You will then inspect the data with your problem in mind and begin to formulate a  project plan. You will then implement the machine learning project plan. \n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build Your DataFrame\n",
    "2. Define Your ML Problem\n",
    "3. Perform exploratory data analysis to understand your data.\n",
    "4. Define Your Project Plan\n",
    "5. Implement Your Project Plan:\n",
    "    * Prepare your data for your model.\n",
    "    * Fit your model to the training data and evaluate your model.\n",
    "    * Improve your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>Confidence in national government</th>\n",
       "      <th>Democratic Quality</th>\n",
       "      <th>Delivery Quality</th>\n",
       "      <th>Standard deviation of ladder by country-year</th>\n",
       "      <th>Standard deviation/Mean of ladder by country-year</th>\n",
       "      <th>GINI index (World Bank estimate)</th>\n",
       "      <th>GINI index (World Bank estimate), average 2000-15</th>\n",
       "      <th>gini of household income reported in Gallup, by wp5-year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>3.723590</td>\n",
       "      <td>7.168690</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>49.209663</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>0.258195</td>\n",
       "      <td>0.612072</td>\n",
       "      <td>-1.929690</td>\n",
       "      <td>-1.655084</td>\n",
       "      <td>1.774662</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2009</td>\n",
       "      <td>4.401778</td>\n",
       "      <td>7.333790</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>49.624432</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.203614</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>0.611545</td>\n",
       "      <td>-2.044093</td>\n",
       "      <td>-1.635025</td>\n",
       "      <td>1.722688</td>\n",
       "      <td>0.391362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.758381</td>\n",
       "      <td>7.386629</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>50.008961</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.137630</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.275324</td>\n",
       "      <td>0.299357</td>\n",
       "      <td>-1.991810</td>\n",
       "      <td>-1.617176</td>\n",
       "      <td>1.878622</td>\n",
       "      <td>0.394803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.327318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.831719</td>\n",
       "      <td>7.415019</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>50.367298</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.175329</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>0.307386</td>\n",
       "      <td>-1.919018</td>\n",
       "      <td>-1.616221</td>\n",
       "      <td>1.785360</td>\n",
       "      <td>0.465942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.782938</td>\n",
       "      <td>7.517126</td>\n",
       "      <td>0.520637</td>\n",
       "      <td>50.709263</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.775620</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>0.435440</td>\n",
       "      <td>-1.842996</td>\n",
       "      <td>-1.404078</td>\n",
       "      <td>1.798283</td>\n",
       "      <td>0.475367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year  Life Ladder  Log GDP per capita  Social support  \\\n",
       "0  Afghanistan  2008     3.723590            7.168690        0.450662   \n",
       "1  Afghanistan  2009     4.401778            7.333790        0.552308   \n",
       "2  Afghanistan  2010     4.758381            7.386629        0.539075   \n",
       "3  Afghanistan  2011     3.831719            7.415019        0.521104   \n",
       "4  Afghanistan  2012     3.782938            7.517126        0.520637   \n",
       "\n",
       "   Healthy life expectancy at birth  Freedom to make life choices  Generosity  \\\n",
       "0                         49.209663                      0.718114    0.181819   \n",
       "1                         49.624432                      0.678896    0.203614   \n",
       "2                         50.008961                      0.600127    0.137630   \n",
       "3                         50.367298                      0.495901    0.175329   \n",
       "4                         50.709263                      0.530935    0.247159   \n",
       "\n",
       "   Perceptions of corruption  Positive affect  Negative affect  \\\n",
       "0                   0.881686         0.517637         0.258195   \n",
       "1                   0.850035         0.583926         0.237092   \n",
       "2                   0.706766         0.618265         0.275324   \n",
       "3                   0.731109         0.611387         0.267175   \n",
       "4                   0.775620         0.710385         0.267919   \n",
       "\n",
       "   Confidence in national government  Democratic Quality  Delivery Quality  \\\n",
       "0                           0.612072           -1.929690         -1.655084   \n",
       "1                           0.611545           -2.044093         -1.635025   \n",
       "2                           0.299357           -1.991810         -1.617176   \n",
       "3                           0.307386           -1.919018         -1.616221   \n",
       "4                           0.435440           -1.842996         -1.404078   \n",
       "\n",
       "   Standard deviation of ladder by country-year  \\\n",
       "0                                      1.774662   \n",
       "1                                      1.722688   \n",
       "2                                      1.878622   \n",
       "3                                      1.785360   \n",
       "4                                      1.798283   \n",
       "\n",
       "   Standard deviation/Mean of ladder by country-year  \\\n",
       "0                                           0.476600   \n",
       "1                                           0.391362   \n",
       "2                                           0.394803   \n",
       "3                                           0.465942   \n",
       "4                                           0.475367   \n",
       "\n",
       "   GINI index (World Bank estimate)  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2                               NaN   \n",
       "3                               NaN   \n",
       "4                               NaN   \n",
       "\n",
       "   GINI index (World Bank estimate), average 2000-15  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "   gini of household income reported in Gallup, by wp5-year  \n",
       "0                                                NaN         \n",
       "1                                           0.441906         \n",
       "2                                           0.327318         \n",
       "3                                           0.336764         \n",
       "4                                           0.344540         "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File names of the four data sets\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "airbnbDataSet_filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(WHRDataSet_filename)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the World Happiness Report dataset, I'm going to be predicting the \"Freedom to make life choices\" numerical feature. This is a supervised learning regression problem because we have the correct labels in our dataset. The features will include country, year, generosity, happiness, corruption, positive and negative affect, confidence in government, and social support. \n",
    "\n",
    "This is an important problem to predict because freedom is a necessary macroeconomic variable that can give some insight into the quality of life and social mobility in a country. However, a company could gain value from this machine learning problem if, for example, it was a media or entertainment company that was looking to expand internationally. By measuring each country's level of freedom, this company can understand which country would be most worthwhile to expand to depending on the level of freedom the population has to consume different types of entertainment and media. A country with less freedom will likely have less freedom to consume diverse media, particularly controversial or political types, while a country with more freedom will likely have fewer regulations and policies in place to prevent the consumption of this company's services. Alternatively, if the company has been established in several countries it can market its products and services to residents of countries with higher levels of freedom who will be more likely to subscribe or consume. Therefore, we can create a model that will predict the current level of freedom within each country to create greater value for this subscription and product based media company. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>Confidence in national government</th>\n",
       "      <th>Democratic Quality</th>\n",
       "      <th>Delivery Quality</th>\n",
       "      <th>Standard deviation of ladder by country-year</th>\n",
       "      <th>Standard deviation/Mean of ladder by country-year</th>\n",
       "      <th>GINI index (World Bank estimate)</th>\n",
       "      <th>GINI index (World Bank estimate), average 2000-15</th>\n",
       "      <th>gini of household income reported in Gallup, by wp5-year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>3.723590</td>\n",
       "      <td>7.168690</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>49.209663</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>0.258195</td>\n",
       "      <td>0.612072</td>\n",
       "      <td>-1.929690</td>\n",
       "      <td>-1.655084</td>\n",
       "      <td>1.774662</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2009</td>\n",
       "      <td>4.401778</td>\n",
       "      <td>7.333790</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>49.624432</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.203614</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>0.611545</td>\n",
       "      <td>-2.044093</td>\n",
       "      <td>-1.635025</td>\n",
       "      <td>1.722688</td>\n",
       "      <td>0.391362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.758381</td>\n",
       "      <td>7.386629</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>50.008961</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.137630</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.275324</td>\n",
       "      <td>0.299357</td>\n",
       "      <td>-1.991810</td>\n",
       "      <td>-1.617176</td>\n",
       "      <td>1.878622</td>\n",
       "      <td>0.394803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.327318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.831719</td>\n",
       "      <td>7.415019</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>50.367298</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.175329</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>0.307386</td>\n",
       "      <td>-1.919018</td>\n",
       "      <td>-1.616221</td>\n",
       "      <td>1.785360</td>\n",
       "      <td>0.465942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.782938</td>\n",
       "      <td>7.517126</td>\n",
       "      <td>0.520637</td>\n",
       "      <td>50.709263</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.775620</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>0.435440</td>\n",
       "      <td>-1.842996</td>\n",
       "      <td>-1.404078</td>\n",
       "      <td>1.798283</td>\n",
       "      <td>0.475367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.690188</td>\n",
       "      <td>7.565154</td>\n",
       "      <td>0.799274</td>\n",
       "      <td>48.949745</td>\n",
       "      <td>0.575884</td>\n",
       "      <td>-0.076716</td>\n",
       "      <td>0.830937</td>\n",
       "      <td>0.711885</td>\n",
       "      <td>0.182288</td>\n",
       "      <td>0.527755</td>\n",
       "      <td>-1.026085</td>\n",
       "      <td>-1.526321</td>\n",
       "      <td>1.964805</td>\n",
       "      <td>0.418918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.555439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.184451</td>\n",
       "      <td>7.562753</td>\n",
       "      <td>0.765839</td>\n",
       "      <td>50.051235</td>\n",
       "      <td>0.642034</td>\n",
       "      <td>-0.045885</td>\n",
       "      <td>0.820217</td>\n",
       "      <td>0.725214</td>\n",
       "      <td>0.239111</td>\n",
       "      <td>0.566209</td>\n",
       "      <td>-0.985267</td>\n",
       "      <td>-1.484067</td>\n",
       "      <td>2.079248</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.601080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.703191</td>\n",
       "      <td>7.556052</td>\n",
       "      <td>0.735800</td>\n",
       "      <td>50.925652</td>\n",
       "      <td>0.667193</td>\n",
       "      <td>-0.094585</td>\n",
       "      <td>0.810457</td>\n",
       "      <td>0.715079</td>\n",
       "      <td>0.178861</td>\n",
       "      <td>0.590012</td>\n",
       "      <td>-0.893078</td>\n",
       "      <td>-1.357514</td>\n",
       "      <td>2.198865</td>\n",
       "      <td>0.593776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.655137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.735400</td>\n",
       "      <td>7.538829</td>\n",
       "      <td>0.768425</td>\n",
       "      <td>51.800068</td>\n",
       "      <td>0.732971</td>\n",
       "      <td>-0.065283</td>\n",
       "      <td>0.723612</td>\n",
       "      <td>0.737636</td>\n",
       "      <td>0.208555</td>\n",
       "      <td>0.699344</td>\n",
       "      <td>-0.863044</td>\n",
       "      <td>-1.371214</td>\n",
       "      <td>2.776363</td>\n",
       "      <td>0.743257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.596690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2017</td>\n",
       "      <td>3.638300</td>\n",
       "      <td>7.538187</td>\n",
       "      <td>0.754147</td>\n",
       "      <td>52.674484</td>\n",
       "      <td>0.752826</td>\n",
       "      <td>-0.066005</td>\n",
       "      <td>0.751208</td>\n",
       "      <td>0.806428</td>\n",
       "      <td>0.224051</td>\n",
       "      <td>0.682647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.656848</td>\n",
       "      <td>0.730244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.581484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1562 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  year  Life Ladder  Log GDP per capita  Social support  \\\n",
       "0     Afghanistan  2008     3.723590            7.168690        0.450662   \n",
       "1     Afghanistan  2009     4.401778            7.333790        0.552308   \n",
       "2     Afghanistan  2010     4.758381            7.386629        0.539075   \n",
       "3     Afghanistan  2011     3.831719            7.415019        0.521104   \n",
       "4     Afghanistan  2012     3.782938            7.517126        0.520637   \n",
       "...           ...   ...          ...                 ...             ...   \n",
       "1557     Zimbabwe  2013     4.690188            7.565154        0.799274   \n",
       "1558     Zimbabwe  2014     4.184451            7.562753        0.765839   \n",
       "1559     Zimbabwe  2015     3.703191            7.556052        0.735800   \n",
       "1560     Zimbabwe  2016     3.735400            7.538829        0.768425   \n",
       "1561     Zimbabwe  2017     3.638300            7.538187        0.754147   \n",
       "\n",
       "      Healthy life expectancy at birth  Freedom to make life choices  \\\n",
       "0                            49.209663                      0.718114   \n",
       "1                            49.624432                      0.678896   \n",
       "2                            50.008961                      0.600127   \n",
       "3                            50.367298                      0.495901   \n",
       "4                            50.709263                      0.530935   \n",
       "...                                ...                           ...   \n",
       "1557                         48.949745                      0.575884   \n",
       "1558                         50.051235                      0.642034   \n",
       "1559                         50.925652                      0.667193   \n",
       "1560                         51.800068                      0.732971   \n",
       "1561                         52.674484                      0.752826   \n",
       "\n",
       "      Generosity  Perceptions of corruption  Positive affect  Negative affect  \\\n",
       "0       0.181819                   0.881686         0.517637         0.258195   \n",
       "1       0.203614                   0.850035         0.583926         0.237092   \n",
       "2       0.137630                   0.706766         0.618265         0.275324   \n",
       "3       0.175329                   0.731109         0.611387         0.267175   \n",
       "4       0.247159                   0.775620         0.710385         0.267919   \n",
       "...          ...                        ...              ...              ...   \n",
       "1557   -0.076716                   0.830937         0.711885         0.182288   \n",
       "1558   -0.045885                   0.820217         0.725214         0.239111   \n",
       "1559   -0.094585                   0.810457         0.715079         0.178861   \n",
       "1560   -0.065283                   0.723612         0.737636         0.208555   \n",
       "1561   -0.066005                   0.751208         0.806428         0.224051   \n",
       "\n",
       "      Confidence in national government  Democratic Quality  Delivery Quality  \\\n",
       "0                              0.612072           -1.929690         -1.655084   \n",
       "1                              0.611545           -2.044093         -1.635025   \n",
       "2                              0.299357           -1.991810         -1.617176   \n",
       "3                              0.307386           -1.919018         -1.616221   \n",
       "4                              0.435440           -1.842996         -1.404078   \n",
       "...                                 ...                 ...               ...   \n",
       "1557                           0.527755           -1.026085         -1.526321   \n",
       "1558                           0.566209           -0.985267         -1.484067   \n",
       "1559                           0.590012           -0.893078         -1.357514   \n",
       "1560                           0.699344           -0.863044         -1.371214   \n",
       "1561                           0.682647                 NaN               NaN   \n",
       "\n",
       "      Standard deviation of ladder by country-year  \\\n",
       "0                                         1.774662   \n",
       "1                                         1.722688   \n",
       "2                                         1.878622   \n",
       "3                                         1.785360   \n",
       "4                                         1.798283   \n",
       "...                                            ...   \n",
       "1557                                      1.964805   \n",
       "1558                                      2.079248   \n",
       "1559                                      2.198865   \n",
       "1560                                      2.776363   \n",
       "1561                                      2.656848   \n",
       "\n",
       "      Standard deviation/Mean of ladder by country-year  \\\n",
       "0                                              0.476600   \n",
       "1                                              0.391362   \n",
       "2                                              0.394803   \n",
       "3                                              0.465942   \n",
       "4                                              0.475367   \n",
       "...                                                 ...   \n",
       "1557                                           0.418918   \n",
       "1558                                           0.496899   \n",
       "1559                                           0.593776   \n",
       "1560                                           0.743257   \n",
       "1561                                           0.730244   \n",
       "\n",
       "      GINI index (World Bank estimate)  \\\n",
       "0                                  NaN   \n",
       "1                                  NaN   \n",
       "2                                  NaN   \n",
       "3                                  NaN   \n",
       "4                                  NaN   \n",
       "...                                ...   \n",
       "1557                               NaN   \n",
       "1558                               NaN   \n",
       "1559                               NaN   \n",
       "1560                               NaN   \n",
       "1561                               NaN   \n",
       "\n",
       "      GINI index (World Bank estimate), average 2000-15  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1557                                              0.432   \n",
       "1558                                              0.432   \n",
       "1559                                              0.432   \n",
       "1560                                              0.432   \n",
       "1561                                              0.432   \n",
       "\n",
       "      gini of household income reported in Gallup, by wp5-year  \n",
       "0                                                   NaN         \n",
       "1                                              0.441906         \n",
       "2                                              0.327318         \n",
       "3                                              0.336764         \n",
       "4                                              0.344540         \n",
       "...                                                 ...         \n",
       "1557                                           0.555439         \n",
       "1558                                           0.601080         \n",
       "1559                                           0.655137         \n",
       "1560                                           0.596690         \n",
       "1561                                           0.581484         \n",
       "\n",
       "[1562 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                                                      object\n",
       "year                                                          int64\n",
       "Life Ladder                                                 float64\n",
       "Log GDP per capita                                          float64\n",
       "Social support                                              float64\n",
       "Healthy life expectancy at birth                            float64\n",
       "Freedom to make life choices                                float64\n",
       "Generosity                                                  float64\n",
       "Perceptions of corruption                                   float64\n",
       "Positive affect                                             float64\n",
       "Negative affect                                             float64\n",
       "Confidence in national government                           float64\n",
       "Democratic Quality                                          float64\n",
       "Delivery Quality                                            float64\n",
       "Standard deviation of ladder by country-year                float64\n",
       "Standard deviation/Mean of ladder by country-year           float64\n",
       "GINI index (World Bank estimate)                            float64\n",
       "GINI index (World Bank estimate), average 2000-15           float64\n",
       "gini of household income reported in Gallup, by wp5-year    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no one hot encoding needed\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                                                       0\n",
       "year                                                          0\n",
       "Life Ladder                                                   0\n",
       "Log GDP per capita                                           27\n",
       "Social support                                               13\n",
       "Healthy life expectancy at birth                              9\n",
       "Freedom to make life choices                                 29\n",
       "Generosity                                                   80\n",
       "Perceptions of corruption                                    90\n",
       "Positive affect                                              18\n",
       "Negative affect                                              12\n",
       "Confidence in national government                           161\n",
       "Democratic Quality                                          171\n",
       "Delivery Quality                                            171\n",
       "Standard deviation of ladder by country-year                  0\n",
       "Standard deviation/Mean of ladder by country-year             0\n",
       "GINI index (World Bank estimate)                            979\n",
       "GINI index (World Bank estimate), average 2000-15           176\n",
       "gini of household income reported in Gallup, by wp5-year    357\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is a small dataset, prioritize features with less missing values\n",
    "features = ['country', 'year', 'Life Ladder', 'Positive affect','Negative affect',\n",
    "                   'Log GDP per capita', 'Social support',\n",
    "                   'Healthy life expectancy at birth',\n",
    "                   'Generosity', 'Perceptions of corruption', 'Freedom to make life choices', 'Confidence in national government']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[features].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'Life Ladder': 'Happiness',\n",
    "            'Log GDP per capita': 'LogGDP',\n",
    "            'Social support': 'Support',\n",
    "            'Healthy life expectancy at birth': 'Life',\n",
    "            'Freedom to make life choices': 'Freedom',\n",
    "            'Perceptions of corruption': 'Corruption',\n",
    "            'Positive affect': 'Positive',\n",
    "            'Negative affect': 'Negative',\n",
    "            'Confidence in national government': 'Government'}\n",
    "\n",
    "df.rename(columns = rename_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'year', 'Happiness', 'Positive', 'Negative', 'LogGDP',\n",
       "       'Support', 'Life', 'Generosity', 'Corruption', 'Freedom', 'Government'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>LogGDP</th>\n",
       "      <th>Support</th>\n",
       "      <th>Life</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Government</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1316.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2011.956687</td>\n",
       "      <td>5.420000</td>\n",
       "      <td>0.711302</td>\n",
       "      <td>0.261857</td>\n",
       "      <td>9.163386</td>\n",
       "      <td>0.809490</td>\n",
       "      <td>62.001041</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.759803</td>\n",
       "      <td>0.728767</td>\n",
       "      <td>0.479019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.355324</td>\n",
       "      <td>1.142543</td>\n",
       "      <td>0.108207</td>\n",
       "      <td>0.079155</td>\n",
       "      <td>1.192839</td>\n",
       "      <td>0.121614</td>\n",
       "      <td>8.297872</td>\n",
       "      <td>0.163358</td>\n",
       "      <td>0.182305</td>\n",
       "      <td>0.143772</td>\n",
       "      <td>0.191053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>2.661718</td>\n",
       "      <td>0.362498</td>\n",
       "      <td>0.094316</td>\n",
       "      <td>6.377396</td>\n",
       "      <td>0.290184</td>\n",
       "      <td>37.766476</td>\n",
       "      <td>-0.322952</td>\n",
       "      <td>0.035198</td>\n",
       "      <td>0.260069</td>\n",
       "      <td>0.078787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>4.556591</td>\n",
       "      <td>0.621561</td>\n",
       "      <td>0.205219</td>\n",
       "      <td>8.197298</td>\n",
       "      <td>0.744283</td>\n",
       "      <td>56.300040</td>\n",
       "      <td>-0.109544</td>\n",
       "      <td>0.706790</td>\n",
       "      <td>0.633800</td>\n",
       "      <td>0.333496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2012.000000</td>\n",
       "      <td>5.306670</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.250367</td>\n",
       "      <td>9.354222</td>\n",
       "      <td>0.833590</td>\n",
       "      <td>63.642756</td>\n",
       "      <td>-0.016110</td>\n",
       "      <td>0.812861</td>\n",
       "      <td>0.744932</td>\n",
       "      <td>0.462192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>6.251656</td>\n",
       "      <td>0.805188</td>\n",
       "      <td>0.307532</td>\n",
       "      <td>10.132988</td>\n",
       "      <td>0.905326</td>\n",
       "      <td>68.420866</td>\n",
       "      <td>0.100445</td>\n",
       "      <td>0.881737</td>\n",
       "      <td>0.842849</td>\n",
       "      <td>0.610397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>7.970892</td>\n",
       "      <td>0.943621</td>\n",
       "      <td>0.590539</td>\n",
       "      <td>11.670484</td>\n",
       "      <td>0.987343</td>\n",
       "      <td>76.536362</td>\n",
       "      <td>0.666991</td>\n",
       "      <td>0.983276</td>\n",
       "      <td>0.985178</td>\n",
       "      <td>0.993604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year    Happiness     Positive     Negative       LogGDP  \\\n",
       "count  1316.000000  1316.000000  1316.000000  1316.000000  1316.000000   \n",
       "mean   2011.956687     5.420000     0.711302     0.261857     9.163386   \n",
       "std       3.355324     1.142543     0.108207     0.079155     1.192839   \n",
       "min    2005.000000     2.661718     0.362498     0.094316     6.377396   \n",
       "25%    2009.000000     4.556591     0.621561     0.205219     8.197298   \n",
       "50%    2012.000000     5.306670     0.724116     0.250367     9.354222   \n",
       "75%    2015.000000     6.251656     0.805188     0.307532    10.132988   \n",
       "max    2017.000000     7.970892     0.943621     0.590539    11.670484   \n",
       "\n",
       "           Support         Life   Generosity   Corruption      Freedom  \\\n",
       "count  1316.000000  1316.000000  1316.000000  1316.000000  1316.000000   \n",
       "mean      0.809490    62.001041     0.004206     0.759803     0.728767   \n",
       "std       0.121614     8.297872     0.163358     0.182305     0.143772   \n",
       "min       0.290184    37.766476    -0.322952     0.035198     0.260069   \n",
       "25%       0.744283    56.300040    -0.109544     0.706790     0.633800   \n",
       "50%       0.833590    63.642756    -0.016110     0.812861     0.744932   \n",
       "75%       0.905326    68.420866     0.100445     0.881737     0.842849   \n",
       "max       0.987343    76.536362     0.666991     0.983276     0.985178   \n",
       "\n",
       "        Government  \n",
       "count  1316.000000  \n",
       "mean      0.479019  \n",
       "std       0.191053  \n",
       "min       0.078787  \n",
       "25%       0.333496  \n",
       "50%       0.462192  \n",
       "75%       0.610397  \n",
       "max       0.993604  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no apparent outliers when observing the data range and standard deviations. Easily measurable features like year and life expectancy\n",
    "# are reasonable\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years range from 2005 to 2017. To ensure there's no feature leakage, I'll need to group by country and take the mean values\n",
    "# so I can drop the year column\n",
    "df = df.groupby(['country']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['year', 'country'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Happiness     150\n",
       "Positive      150\n",
       "Negative      150\n",
       "LogGDP        150\n",
       "Support       150\n",
       "Life          150\n",
       "Generosity    150\n",
       "Corruption    150\n",
       "Freedom       150\n",
       "Government    150\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>LogGDP</th>\n",
       "      <th>Support</th>\n",
       "      <th>Life</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Government</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.441156</td>\n",
       "      <td>-1.290416</td>\n",
       "      <td>0.563216</td>\n",
       "      <td>-1.400973</td>\n",
       "      <td>-2.346422</td>\n",
       "      <td>-1.263620</td>\n",
       "      <td>0.711109</td>\n",
       "      <td>0.425767</td>\n",
       "      <td>-1.395381</td>\n",
       "      <td>-0.542547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.568824</td>\n",
       "      <td>-0.649639</td>\n",
       "      <td>0.746548</td>\n",
       "      <td>0.110168</td>\n",
       "      <td>-0.828024</td>\n",
       "      <td>0.822887</td>\n",
       "      <td>-0.510432</td>\n",
       "      <td>0.699230</td>\n",
       "      <td>-0.445160</td>\n",
       "      <td>-0.491628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.875071</td>\n",
       "      <td>-0.962860</td>\n",
       "      <td>1.293381</td>\n",
       "      <td>-0.342747</td>\n",
       "      <td>-0.521826</td>\n",
       "      <td>-1.157025</td>\n",
       "      <td>-0.552734</td>\n",
       "      <td>0.650629</td>\n",
       "      <td>-2.078801</td>\n",
       "      <td>-0.559292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956730</td>\n",
       "      <td>1.334045</td>\n",
       "      <td>0.152024</td>\n",
       "      <td>0.566568</td>\n",
       "      <td>0.867160</td>\n",
       "      <td>0.640552</td>\n",
       "      <td>-1.045763</td>\n",
       "      <td>0.522167</td>\n",
       "      <td>0.204681</td>\n",
       "      <td>-0.541753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.906080</td>\n",
       "      <td>-1.666829</td>\n",
       "      <td>2.487284</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.791082</td>\n",
       "      <td>0.329861</td>\n",
       "      <td>-1.290175</td>\n",
       "      <td>0.737398</td>\n",
       "      <td>-1.585973</td>\n",
       "      <td>-1.082014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.895300</td>\n",
       "      <td>1.161179</td>\n",
       "      <td>-0.651038</td>\n",
       "      <td>0.476135</td>\n",
       "      <td>0.999033</td>\n",
       "      <td>0.331054</td>\n",
       "      <td>-1.287391</td>\n",
       "      <td>0.212314</td>\n",
       "      <td>-0.454059</td>\n",
       "      <td>-0.400754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.032168</td>\n",
       "      <td>-0.829590</td>\n",
       "      <td>-0.901440</td>\n",
       "      <td>-0.593541</td>\n",
       "      <td>0.102052</td>\n",
       "      <td>0.443223</td>\n",
       "      <td>0.131420</td>\n",
       "      <td>0.157766</td>\n",
       "      <td>1.076620</td>\n",
       "      <td>1.904675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-1.245015</td>\n",
       "      <td>-1.606749</td>\n",
       "      <td>0.529570</td>\n",
       "      <td>-0.736457</td>\n",
       "      <td>-0.920283</td>\n",
       "      <td>-0.885338</td>\n",
       "      <td>-0.998918</td>\n",
       "      <td>0.461794</td>\n",
       "      <td>-0.682164</td>\n",
       "      <td>-0.345974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.630551</td>\n",
       "      <td>0.141441</td>\n",
       "      <td>0.186857</td>\n",
       "      <td>-0.848448</td>\n",
       "      <td>-0.455610</td>\n",
       "      <td>-1.406523</td>\n",
       "      <td>-0.108210</td>\n",
       "      <td>0.454314</td>\n",
       "      <td>0.175031</td>\n",
       "      <td>0.301388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-1.203539</td>\n",
       "      <td>0.110737</td>\n",
       "      <td>-0.707519</td>\n",
       "      <td>-1.404041</td>\n",
       "      <td>0.087286</td>\n",
       "      <td>-1.792405</td>\n",
       "      <td>-0.464353</td>\n",
       "      <td>0.555025</td>\n",
       "      <td>-1.240986</td>\n",
       "      <td>-0.279929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Happiness  Positive  Negative    LogGDP   Support      Life  Generosity  \\\n",
       "0    -1.441156 -1.290416  0.563216 -1.400973 -2.346422 -1.263620    0.711109   \n",
       "1    -0.568824 -0.649639  0.746548  0.110168 -0.828024  0.822887   -0.510432   \n",
       "2    -0.875071 -0.962860  1.293381 -0.342747 -0.521826 -1.157025   -0.552734   \n",
       "3     0.956730  1.334045  0.152024  0.566568  0.867160  0.640552   -1.045763   \n",
       "4    -0.906080 -1.666829  2.487284 -0.185695 -0.791082  0.329861   -1.290175   \n",
       "..         ...       ...       ...       ...       ...       ...         ...   \n",
       "145   0.895300  1.161179 -0.651038  0.476135  0.999033  0.331054   -1.287391   \n",
       "146   0.032168 -0.829590 -0.901440 -0.593541  0.102052  0.443223    0.131420   \n",
       "147  -1.245015 -1.606749  0.529570 -0.736457 -0.920283 -0.885338   -0.998918   \n",
       "148  -0.630551  0.141441  0.186857 -0.848448 -0.455610 -1.406523   -0.108210   \n",
       "149  -1.203539  0.110737 -0.707519 -1.404041  0.087286 -1.792405   -0.464353   \n",
       "\n",
       "     Corruption   Freedom  Government  \n",
       "0      0.425767 -1.395381   -0.542547  \n",
       "1      0.699230 -0.445160   -0.491628  \n",
       "2      0.650629 -2.078801   -0.559292  \n",
       "3      0.522167  0.204681   -0.541753  \n",
       "4      0.737398 -1.585973   -1.082014  \n",
       "..          ...       ...         ...  \n",
       "145    0.212314 -0.454059   -0.400754  \n",
       "146    0.157766  1.076620    1.904675  \n",
       "147    0.461794 -0.682164   -0.345974  \n",
       "148    0.454314  0.175031    0.301388  \n",
       "149    0.555025 -1.240986   -0.279929  \n",
       "\n",
       "[150 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "transformed_data = scaler.fit_transform(df)\n",
    "\n",
    "df_scaled = pd.DataFrame(transformed_data, columns = df.columns, index = df.index)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>LogGDP</th>\n",
       "      <th>Support</th>\n",
       "      <th>Life</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "      <th>Government</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.441156</td>\n",
       "      <td>-1.290416</td>\n",
       "      <td>0.563216</td>\n",
       "      <td>-1.400973</td>\n",
       "      <td>-2.346422</td>\n",
       "      <td>-1.263620</td>\n",
       "      <td>0.711109</td>\n",
       "      <td>0.425767</td>\n",
       "      <td>-0.542547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.568824</td>\n",
       "      <td>-0.649639</td>\n",
       "      <td>0.746548</td>\n",
       "      <td>0.110168</td>\n",
       "      <td>-0.828024</td>\n",
       "      <td>0.822887</td>\n",
       "      <td>-0.510432</td>\n",
       "      <td>0.699230</td>\n",
       "      <td>-0.491628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.875071</td>\n",
       "      <td>-0.962860</td>\n",
       "      <td>1.293381</td>\n",
       "      <td>-0.342747</td>\n",
       "      <td>-0.521826</td>\n",
       "      <td>-1.157025</td>\n",
       "      <td>-0.552734</td>\n",
       "      <td>0.650629</td>\n",
       "      <td>-0.559292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956730</td>\n",
       "      <td>1.334045</td>\n",
       "      <td>0.152024</td>\n",
       "      <td>0.566568</td>\n",
       "      <td>0.867160</td>\n",
       "      <td>0.640552</td>\n",
       "      <td>-1.045763</td>\n",
       "      <td>0.522167</td>\n",
       "      <td>-0.541753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.906080</td>\n",
       "      <td>-1.666829</td>\n",
       "      <td>2.487284</td>\n",
       "      <td>-0.185695</td>\n",
       "      <td>-0.791082</td>\n",
       "      <td>0.329861</td>\n",
       "      <td>-1.290175</td>\n",
       "      <td>0.737398</td>\n",
       "      <td>-1.082014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.895300</td>\n",
       "      <td>1.161179</td>\n",
       "      <td>-0.651038</td>\n",
       "      <td>0.476135</td>\n",
       "      <td>0.999033</td>\n",
       "      <td>0.331054</td>\n",
       "      <td>-1.287391</td>\n",
       "      <td>0.212314</td>\n",
       "      <td>-0.400754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.032168</td>\n",
       "      <td>-0.829590</td>\n",
       "      <td>-0.901440</td>\n",
       "      <td>-0.593541</td>\n",
       "      <td>0.102052</td>\n",
       "      <td>0.443223</td>\n",
       "      <td>0.131420</td>\n",
       "      <td>0.157766</td>\n",
       "      <td>1.904675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-1.245015</td>\n",
       "      <td>-1.606749</td>\n",
       "      <td>0.529570</td>\n",
       "      <td>-0.736457</td>\n",
       "      <td>-0.920283</td>\n",
       "      <td>-0.885338</td>\n",
       "      <td>-0.998918</td>\n",
       "      <td>0.461794</td>\n",
       "      <td>-0.345974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.630551</td>\n",
       "      <td>0.141441</td>\n",
       "      <td>0.186857</td>\n",
       "      <td>-0.848448</td>\n",
       "      <td>-0.455610</td>\n",
       "      <td>-1.406523</td>\n",
       "      <td>-0.108210</td>\n",
       "      <td>0.454314</td>\n",
       "      <td>0.301388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-1.203539</td>\n",
       "      <td>0.110737</td>\n",
       "      <td>-0.707519</td>\n",
       "      <td>-1.404041</td>\n",
       "      <td>0.087286</td>\n",
       "      <td>-1.792405</td>\n",
       "      <td>-0.464353</td>\n",
       "      <td>0.555025</td>\n",
       "      <td>-0.279929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Happiness  Positive  Negative    LogGDP   Support      Life  Generosity  \\\n",
       "0    -1.441156 -1.290416  0.563216 -1.400973 -2.346422 -1.263620    0.711109   \n",
       "1    -0.568824 -0.649639  0.746548  0.110168 -0.828024  0.822887   -0.510432   \n",
       "2    -0.875071 -0.962860  1.293381 -0.342747 -0.521826 -1.157025   -0.552734   \n",
       "3     0.956730  1.334045  0.152024  0.566568  0.867160  0.640552   -1.045763   \n",
       "4    -0.906080 -1.666829  2.487284 -0.185695 -0.791082  0.329861   -1.290175   \n",
       "..         ...       ...       ...       ...       ...       ...         ...   \n",
       "145   0.895300  1.161179 -0.651038  0.476135  0.999033  0.331054   -1.287391   \n",
       "146   0.032168 -0.829590 -0.901440 -0.593541  0.102052  0.443223    0.131420   \n",
       "147  -1.245015 -1.606749  0.529570 -0.736457 -0.920283 -0.885338   -0.998918   \n",
       "148  -0.630551  0.141441  0.186857 -0.848448 -0.455610 -1.406523   -0.108210   \n",
       "149  -1.203539  0.110737 -0.707519 -1.404041  0.087286 -1.792405   -0.464353   \n",
       "\n",
       "     Corruption  Government  \n",
       "0      0.425767   -0.542547  \n",
       "1      0.699230   -0.491628  \n",
       "2      0.650629   -0.559292  \n",
       "3      0.522167   -0.541753  \n",
       "4      0.737398   -1.082014  \n",
       "..          ...         ...  \n",
       "145    0.212314   -0.400754  \n",
       "146    0.157766    1.904675  \n",
       "147    0.461794   -0.345974  \n",
       "148    0.454314    0.301388  \n",
       "149    0.555025   -0.279929  \n",
       "\n",
       "[150 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_scaled['Freedom']\n",
    "X = df_scaled.drop(columns = 'Freedom')\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data? \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My new feature list includes happiness, positive and negative affect, log GDP, support, life, generosity, government, and corruption. Though there were other features available, many of the other features had a large volume of missing values. Since this is a small dataset, rather than drop the missing values and have fewer examples to train on, I didn't use these features. Since my features were all numerical values, except Country, I didn't have to perform any one hot encoding. Because there were 150 unique countries, I ultimately dropped the country column after aggregating the examples by country. However, since year information was available, to avoid feature leakage by predicting historical data using data from future events, I grouped the examples by country, averaged the values across the years, and reset the index. As such, our data frame now contains information for 150 unique countries. Since I plan to use KNN during model selection, all values were scaled to minimize noise and avoid giving extra importance to features with larger scales (like life). Since this is a regression problem, our primary metrics to evaluate our model on are the $R^2$ value, a measure of our model's explanatory power, and the root mean squared error as a measure of loss.\n",
    "\n",
    "I plan to first utilize the random forest regressor in order to gain insight into feature importance and exclude any features that are irrelevant or add little value. Additionally, since we only have 150 examples, we might expect that a random forest would perform well because each random forest is likely to overfit the data but the bagging technique will average out the errors across the different models. Additionally, it uses bootstrapping which is sampling with replacement so each example can be used more than once to train each model. \n",
    "\n",
    "After the random forest regressor, I'll remove any features with less than a 1% relevance and use the remaining features for the model selection process. Since this is a regression problem, I can utilize linear regression, SGD regression, KNN, and a stacked model that jointly uses linear regression and decision trees. This will be an empirical process where I will test which model performs best on the training and test sets in maximizing the $R^2$ value and minimizing the RMSE. Once I determine the best model, I'll train my model by using a grid search to fine-tune the hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" # suppress info and warning messages\n",
    "import tensorflow.keras as keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random forest regressor object and use default values including criterion as squared error\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# fit the model to the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_rf_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Root Mean Squared Error: 0.5993876738888825\n",
      "[LR] R2: 0.6402937383445193\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model's predictions\n",
    "\n",
    "# Compute the RMSE using mean_squared_error()\n",
    "rf_rmse = root_mean_squared_error(y_test, y_rf_pred)\n",
    "\n",
    "# Compute the R2 score using r2_score()\n",
    "rf_r2 = r2_score(y_test, y_rf_pred)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {0}'.format(rf_rmse))\n",
    "print('[LR] R2: {0}'.format(rf_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>0.440390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Government</td>\n",
       "      <td>0.141898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happiness</td>\n",
       "      <td>0.098032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Generosity</td>\n",
       "      <td>0.080990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support</td>\n",
       "      <td>0.069942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Corruption</td>\n",
       "      <td>0.058271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogGDP</td>\n",
       "      <td>0.041868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>0.039212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Life</td>\n",
       "      <td>0.029397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature  Importance\n",
       "1    Positive    0.440390\n",
       "8  Government    0.141898\n",
       "0   Happiness    0.098032\n",
       "6  Generosity    0.080990\n",
       "4     Support    0.069942\n",
       "7  Corruption    0.058271\n",
       "3      LogGDP    0.041868\n",
       "2    Negative    0.039212\n",
       "5        Life    0.029397"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize feature importance\n",
    "features_importances = rf_model.feature_importances_\n",
    "feature_imp_df = pd.DataFrame({'Feature': X.columns, 'Importance': features_importances}).sort_values('Importance', ascending=False)\n",
    "feature_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a bar plot for feature importance\n",
    "plt.barh(X.columns, features_importances)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the feature importances, it looks like no feature has less than a 1% feature importance value so I'll continue using all the features in my models. Positive affect has the highest feature importance, and then confidence in government, generosity, social support, and happiness. This makes intuitive sense freedom is likely strongly associated with positive affect, government, and social welfare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the LinearRegression model object\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# fit the model to the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_lr_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Root Mean Squared Error: 0.574359922400768\n",
      "[LR] R2: 0.6697060346541555\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model's predictions\n",
    "\n",
    "# Compute the RMSE using mean_squared_error()\n",
    "lr_rmse = root_mean_squared_error(y_test, y_lr_pred)\n",
    "\n",
    "# Compute the R2 score using r2_score()\n",
    "lr_r2 = r2_score(y_test, y_lr_pred)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {0}'.format(lr_rmse))\n",
    "print('[LR] R2: {0}'.format(lr_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the SGDRegressor model object\n",
    "SGD_model = SGDRegressor(loss='squared_error', max_iter=1000, tol=1e-3, learning_rate='constant')\n",
    "\n",
    "# fit the model to the training data\n",
    "SGD_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_SGD_pred = SGD_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Root Mean Squared Error: 0.5605957874891968\n",
      "[LR] R2: 0.6853468798459913\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model's predictions\n",
    "\n",
    "# Compute the RMSE using mean_squared_error()\n",
    "SGD_rmse = root_mean_squared_error(y_test, y_SGD_pred)\n",
    "\n",
    "# Compute the R2 score using r2_score()\n",
    "SGD_r2 = r2_score(y_test, y_SGD_pred)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {0}'.format(SGD_rmse))\n",
    "print('[LR] R2: {0}'.format(SGD_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the KNeighborsRegressor model object\n",
    "KNN_model = KNeighborsRegressor(n_neighbors = 10)\n",
    "\n",
    "# fit the model to the training data\n",
    "KNN_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_KNN_pred = KNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Root Mean Squared Error: 0.612437332660427\n",
      "[LR] R2: 0.6244604380582186\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model's predictions\n",
    "\n",
    "# Compute the RMSE using mean_squared_error()\n",
    "KNN_rmse = root_mean_squared_error(y_test, y_KNN_pred)\n",
    "\n",
    "# Compute the R2 score using r2_score()\n",
    "KNN_r2 = r2_score(y_test, y_KNN_pred)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {0}'.format(KNN_rmse))\n",
    "print('[LR] R2: {0}'.format(KNN_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"DT\", DecisionTreeRegressor(max_depth=8, min_samples_leaf=25)),\n",
    "              (\"LR\", LinearRegression())\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the StackRegressor model object\n",
    "stack_model = StackingRegressor(estimators = estimators, passthrough = False)\n",
    "\n",
    "# fit the model to the training data\n",
    "stack_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_stack_pred = stack_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Root Mean Squared Error: 0.5807473922206116\n",
      "[LR] R2: 0.6623187713679685\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model's predictions\n",
    "\n",
    "# Compute the RMSE using mean_squared_error()\n",
    "stack_rmse = root_mean_squared_error(y_test, y_stack_pred)\n",
    "\n",
    "# Compute the R2 score using r2_score()\n",
    "stack_r2 = r2_score(y_test, y_stack_pred)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {0}'.format(stack_rmse))\n",
    "print('[LR] R2: {0}'.format(stack_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE_Results = [rf_rmse, lr_rmse, SGD_rmse, KNN_rmse, stack_rmse]\n",
    "R2_Results = [rf_r2, lr_r2, SGD_r2, KNN_r2, stack_r2]\n",
    "\n",
    "rg= np.arange(5)\n",
    "width = 0.35\n",
    "\n",
    "# 1. Create bar plot with RMSE results\n",
    "plt.bar(rg, RMSE_Results, width, color = 'red', label='RMSE')\n",
    "\n",
    "# 2. Create bar plot with R2 results\n",
    "plt.bar(rg+width, R2_Results, width, color = 'blue', label='R2')\n",
    "\n",
    "labels = ['RF', 'LR', 'SGD', 'KNN', 'Stacking']\n",
    "plt.xticks(rg + width/2, labels)\n",
    "\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"RMSE/R2\")\n",
    "\n",
    "\n",
    "plt.ylim([0,1])\n",
    "plt.title('Model Performance')\n",
    "plt.legend(loc='upper left', ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "From the figure, the stochastic gradient descent regression model performed the best by outputting the highest $R^2$ value, 0.685, in relation to the label and minimizing the root mean squared error at 0.561. However, linear regression performed very similarly, with a difference of 0.02 in both the $R^2$ value and the RMSE. In some instances when I've run these models, linear regression marginally outperformed stochastic gradient regression. The stacking and random forest methods performed the next best, which makes sense because these are ensemble methods that train many different individual models and aggregate the results which has the effect of averaging out the errors. For my final model, I'm going to train the stochastic gradient descent model because it performed the best out of all of our models and it has more hyperparameters that I can tun in a grid search in comparison to linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "To train my stochastic gradient descent model, I'm going to fine-tune the alpha hyperparameter, which is the constant multiplied by the regularization term and controls the strength of the regularization, max iterations, which affects the number of passes over the training data (epochs), and learning rate. The learning rate hyperparameter determines how the learning rate will change over epochs. The default hyperparameter for alpha is 0.0001, the default max iterations is 1000 and the default learning rate is invscaling where eta = eta0 / pow(t, power_t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha': [0.0001, 0.001, 0.01], 'max_iter': [500, 1000, 1500, 2000]}\n",
    "sgd_model = SGDRegressor(loss='squared_error', tol=1e-3, learning_rate='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done :)\n"
     ]
    }
   ],
   "source": [
    "sgd_grid = GridSearchCV(sgd_model, param_grid, cv = 5, scoring = 'neg_root_mean_squared_error')\n",
    "sgd_grid_search = sgd_grid.fit(X_train, y_train)\n",
    "print('Done :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DT] RMSE for the best model is : 0.60\n"
     ]
    }
   ],
   "source": [
    "rmse_DT = -1 * sgd_grid_search.best_score_\n",
    "print(\"[DT] RMSE for the best model is : {:.2f}\".format(rmse_DT) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'max_iter': 2000}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_best_params = sgd_grid.best_params_\n",
    "\n",
    "sgd_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SGDRegressor(loss='squared_error', tol=1e-3, alpha = sgd_best_params['alpha'], learning_rate='constant', max_iter = sgd_best_params['max_iter'])\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_best_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Root Mean Squared Error: 0.5535358478908204\n",
      "[LR] R2: 0.693222230029619\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model's predictions\n",
    "\n",
    "# Compute the RMSE using mean_squared_error()\n",
    "best_rmse = root_mean_squared_error(y_test, y_best_pred)\n",
    "\n",
    "# Compute the R2 score using r2_score()\n",
    "best_r2 = r2_score(y_test, y_best_pred)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {0}'.format(best_rmse))\n",
    "print('[LR] R2: {0}'.format(best_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training my model using hyperparameter tuning, my trained stochastic gradient descent model had a regularization of 0.01 rather than the default 0.001 and a max iteration of 2000. Additionally, it performed better than our initial SGD model with an $R^2$ value of 0.693, nearly 0.01 greater, and an RMSE value of 0.553. This model minimized the root mean squared error by about 0.008 more than our initial model. Overall, our model is able to explain about 70% of the variability in our label, freedom."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
